# Critique by Design

In this project, I will be critiquing a visualization I found publicly available online using the [Data Visualization Effectiveness Profile](http://www.perceptualedge.com/articles/visual_business_intelligence/data_visualization_effectiveness_profile.pdf) method and then taking the visual through a rework process with the end result being a more effective data visualiztion. 

"When we create a data visualization, we do so with particular objectives in mind—or at least we should. We visualize data to help people understand particular facts and what they mean. We design the visualization to feature those facts in a way that can be understood and to a degree that is useful. Any data set can be visualized in many ways, depending on the meanings contained therein that we choose to communicate. Visualizing data is an act of interpretation. What we choose to include and how we display it transforms data into a message.” – Stephen Few, Perceptual Edge

# The Visual 

![alt text](/BrookingsViz.JPG)

The visual chosen for this critique project appeared in ["Black-white disparity in student loan debt more than triples after graduation"](https://www.brookings.edu/research/black-white-disparity-in-student-loan-debt-more-than-triples-after-graduation/
) by Judith Scott-Clayton and Jing Li, published October 20, 2016. 


# The Critique

Ratings by Effectiveness Measure:
Usefulness	10
Completeness	8
Perceptibility	5
Truthfulness	8
Intuitiveness	7
Aesthetics	1
Engagement	3

Describe your overall observations about the data visualization here.  What stood out to you?  What did you find worked really well?  What didn't?  What, if anything, would you do differently?

Overall, I find this visualization displays important information that is relevant to the article, but it is an ugly, overwhelming graphic. When I first saw the visualization, my eyes did not know where to go - they darted around. There is a lot of bold text and there is no hierarchy to it (title, subtitles, labels are all the same size and style). It takes a minute to understand that there are four graphs, representing unique types of data with different y-axis scales (panel B is missing a y-axis label entirely). I like the depiction of the separate graduation years in side-by-side bars but I do not think the blue and red coloring works well, since the red/blue typically is used to represent political parties. Since the x-axes data is categorical, I would put the bars in order from highest to smallest value by 2012 graduation cohort. To improve the visual appeal of the graph, I would remove the bold text and use color to highlight the major comparison points (black and white groups). I would also probably remove panel D because the data is filtered to undergraduate loans only, which makes it less cohesive with the other parts.  

Who is the primary audience for this tool?  Do you think this visualization is effective for reaching that audience?  Why or why not?

The primary audience for this visualization is anyone interested in research on student loan debt and related policy implications (academics, think tanks, policy makers, and the general public). I do not feel the visual is effective in reaching a reader that is skimming through the article like a Hill staffer or member of the press, but it is more so accessible to an individual researcher who has the time to read the details of the article and absorb all the complexities of the graph. If the visualization was made more engaging and simple, it could reach a broader audience.  

Final thoughts: how successful what this method at evaluating the data visualization you selected? Are there measures you feel are missing or not being captured here?  What would you change?

The data visualization effectiveness profile required me to look at aspects of the visualization that I would not have evaluated on my own, specifically the usefulness and completeness measures. For that reason, I found the method useful in aiding a comprehensive critique. However, I enjoyed the Good Charts model of conducting a preliminary review, then requiring a “search for more.” Additionally, I felt some of the measures combined quite a few characteristics. I would recommend splitting completeness into two measures, one measuring for relevance of information provided and one measuring intended level of understanding. 


# The Rework and Wireframe




# The Redesign 



[Click here to go back to the main portfolio page](/portfolio.html)
